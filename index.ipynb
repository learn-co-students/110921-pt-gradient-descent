{"cells": [{"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "9a7141bc16c78c2cbe3925fd27b64699", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["# Calculus, Cost Function, and Gradient Descent"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "c9805014c42291e47d89a0e3e45a4010", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["![best fit line](visuals/best_fit_line.png)\n", "\n", "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n", "\n", "\n", "\n", "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n", "\n", "![](visuals/cost_curve.png)\n", "\n", "where RSS is defined as the residual sum of squares:\n", "\n", "$$ \n", "\\begin{align}\n", "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n", "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n", "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n", "\\end{align}\n", "$$ "]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "0e0fd36124a7212af7ef3cca03ccfb40", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 1. What is a more generalized name for the RSS curve above? How is it related to machine learning models?"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"nbgrader": {"grade": false, "grade_id": "8bf38bfa82409e1d3eda85c7414d4e6d", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The residual sum of squares curve above is a specific example of a cost curve. \n", "\n", "When training machine learning models, the goal is to minimize the cost curve.\n"]}], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "\n", "print(\n", "'''The residual sum of squares curve above is a specific example of a cost curve. \n", "\n", "When training machine learning models, the goal is to minimize the cost curve.'''\n", ")", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "28db3316c2dcd218d47a5455e44e61e8", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "3f003514296b2b97f3638e765ecc1d36", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 2. Would you rather choose a $m$ value of 0.08 or 0.05 from the RSS curve up above?   What is the relation between the position on the cost curve, the error, and the slope `m` of the regression?"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"nbgrader": {"grade": false, "grade_id": "ec4bf24ebc6e2dc9ac35b4e54a8b7044", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "It would be better to have a value of 0.05 rather than 0.08 in the cost curve above. \n", "The reason for this is that the RSS is lower for the value of 0.05. \n", "\n", "As m changes values from 0.00 to 0.10, the Residual Sum of Squares is changing.\n", "\n", "The higher the value of the RSS, the worse the model is performing.\n", "\n", "So, the minimum RSS value which occurs ~ an m of .05 indicates it's that slope\n", "which gives us the best fit for this model\n", "\n"]}], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "print('''\n", "It would be better to have a value of 0.05 rather than 0.08 in the cost curve above. \n", "The reason for this is that the RSS is lower for the value of 0.05. \n", "\n", "As m changes values from 0.00 to 0.10, the Residual Sum of Squares is changing.\n", "\n", "The higher the value of the RSS, the worse the model is performing.\n", "\n", "So, the minimum RSS value which occurs ~ an m of .05 indicates it's that slope\n", "which gives us the best fit for this model\n", "''')", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "91a36bd3bc07b11e795a190ee7e05084", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "7a704cf515e88df1d39d2c7c1c566fb1", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["![](visuals/gd.png)\n", "\n", "### 3. Using the gradient descent visual from above, explain why the distance between each step is getting smaller as more steps occur with gradient descent."]}, {"cell_type": "code", "execution_count": 7, "metadata": {"nbgrader": {"grade": false, "grade_id": "64b1c28718178fde220c60fa8f7429b4", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "The distance between the steps is getting smaller because the slope gradually \n", "becomes less and less steep as iterated points for \"m\" get closer to finding the minimum.\n", "\n", "Subtracting the derivative - the slope at a given point - thus means subtracting\n", "a smaller and smaller value, which translates to smaller and smaller distances\n", "between iterated points on the cost curve.  \n", "\n"]}], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "print('''\n", "The distance between the steps is getting smaller because the slope gradually \n", "becomes less and less steep as iterated points for \"m\" get closer to finding the \n", "minimum RSS value.\n", "\n", "Subtracting the derivative - the slope at a given point - thus means subtracting\n", "a smaller and smaller value, which translates to smaller and smaller distances\n", "between iterated points on the cost curve.  \n", "''')", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "710360161f65d4f41552c296b55a59c7", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "4628880b5f7e4aa70c43174ac3cfe50a", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["### 4. What is the purpose of a learning rate in gradient descent? Explain how a very small and a very large learning rate would affect the gradient descent."]}, {"cell_type": "code", "execution_count": 5, "metadata": {"nbgrader": {"grade": false, "grade_id": "c3199002b9030e5ea3cb54105e9a13e4", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Learning rate is a number that is multiplied by each step that \n", "is taken during gradient descent. \n", "\n", "If the learning rate is smaller, the step sizes will become smaller. \n", "If the learning rate is larger, the step sizes will be larger. \n", "\n", "Learning rate is present in gradient descent to help ensure that an \n", "optimal minimum on the cost curve is discovered.\n", "\n"]}], "source": ["### BEGIN SOLUTION\n\n", "\nfrom test_scripts.test_class import Test\ntest = Test()\n\n", "\n", "print('''\n", "Learning rate is a number that is multiplied by each step that \n", "is taken during gradient descent. \n", "\n", "If the learning rate is smaller, the step sizes will become smaller. \n", "If the learning rate is larger, the step sizes will be larger. \n", "\n", "Learning rate is present in gradient descent to help ensure that an \n", "optimal minimum on the cost curve is discovered.\n", "''')", "\n\ntest.save()\n\n", "\n\n### END SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "e1be5c56d5753367084c5de7bfada348", "locked": true, "points": 1, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL", "\n", "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS", "\n", "\n", "### BEGIN HIDDEN TESTS", "\n", "\nfrom test_scripts.test_class import Test\n", "test = Test()\n\n", "test.run_test()\n\n", "\n", "### END HIDDEN TESTS"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}